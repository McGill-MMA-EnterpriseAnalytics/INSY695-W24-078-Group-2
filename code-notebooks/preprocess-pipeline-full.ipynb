{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('final-weather-flight-data/full_dataset_YUL-Flights-Weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Status', 'Departure Gate', 'Departure Delay (min)',\n",
       "       'Scheduled Departure Time', 'Arrival IATA Code', 'Airline Name',\n",
       "       'Temperature', 'Feels Like', 'Pressure', 'Humidity', 'Wind Speed',\n",
       "       'Wind Degree', 'Clouds', 'Weather Main', 'Rain 1h', 'Snow 1h'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PrudenceC\\AppData\\Local\\Temp\\ipykernel_26904\\3076053184.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Season'] = pd.cut(df['Scheduled Departure Time'].dt.month,\n",
      "C:\\Users\\PrudenceC\\AppData\\Local\\Temp\\ipykernel_26904\\3076053184.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Weekend Departure'] = df['Weekday of Departure'].isin(['Saturday', 'Sunday']).astype(int)\n",
      "C:\\Users\\PrudenceC\\AppData\\Local\\Temp\\ipykernel_26904\\3076053184.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Visibility'] = np.where((df['Weather Main'].isin(['Fog', 'Mist', 'Haze', 'Snow', 'Rain'])), 'Low', 'High')\n"
     ]
    }
   ],
   "source": [
    "# Define a function to feature engineer, drop unwanted columns, and filter rows\n",
    "def custom_preprocess_data(df):\n",
    "    # Convert Scheduled Departure Time and Estimated Departure Time to datetime\n",
    "    df['Scheduled Departure Time'] = pd.to_datetime(df['Scheduled Departure Time'])\n",
    "    #df['Estimated Departure Time'] = pd.to_datetime(df['Estimated Departure Time'])\n",
    "    \n",
    "    # Calculate the difference in minutes\n",
    "    # df['Estimated Departure Delay (min)'] = (df['Estimated Departure Time'] - df['Scheduled Departure Time']).dt.total_seconds() / 60\n",
    "\n",
    "    # Calculate the time of day\n",
    "    df['Departure Time of Day'] = pd.cut(df['Scheduled Departure Time'].dt.hour, \n",
    "                                     bins=[0, 6, 12, 18, 24], \n",
    "                                     labels=['Night', 'Morning', 'Afternoon', 'Evening'], \n",
    "                                     right=False)\n",
    "\n",
    "    # Weekday of departure\n",
    "    df['Weekday of Departure'] = df['Scheduled Departure Time'].dt.day_name()\n",
    "\n",
    "    # Calculate weather severety\n",
    "    df['Weather Severity'] = np.where((df['Rain 1h'] > 0) | (df['Snow 1h'] > 0), 'Bad', 'Good')\n",
    "\n",
    "    # Filter out detinations with a frequency less than 100\n",
    "    destintaiton_counts = df['Arrival IATA Code'].value_counts()\n",
    "    destinations_to_keep = destintaiton_counts[destintaiton_counts >= 100].index\n",
    "    df = df[df['Arrival IATA Code'].isin(destinations_to_keep)]\n",
    "\n",
    "    # Filter out infrequent airlines\n",
    "    # airline_counts = df['Airline Name'].value_counts()\n",
    "    # airlines_to_keep = airline_counts[airline_counts >= 50].index\n",
    "    # df = df[df['Airline Name'].isin(airlines_to_keep)]\n",
    "\n",
    "    # Feature engineering: Create a feature for delay status\n",
    "    # df['Delay Status'] = pd.cut(df['Departure Delay (min)'], \n",
    "    #                             bins=[-np.inf, 0, 15, 60, np.inf], \n",
    "    #                             labels=['On Time', 'Slight Delay', 'Moderate Delay', 'Severe Delay'])\n",
    "\n",
    "    # Feature engineering: Create a feature for season based on month\n",
    "    df['Season'] = pd.cut(df['Scheduled Departure Time'].dt.month, \n",
    "                          bins=[0, 3, 6, 9, 12], \n",
    "                          labels=['Winter', 'Spring', 'Summer', 'Fall'], \n",
    "                          right=False)\n",
    "\n",
    "    # Feature engineering: Create a binary feature for weekend departure\n",
    "    df['Weekend Departure'] = df['Weekday of Departure'].isin(['Saturday', 'Sunday']).astype(int)\n",
    "\n",
    "    # Feature engineering: Create a feature for visibility based on weather conditions\n",
    "    df['Visibility'] = np.where((df['Weather Main'].isin(['Fog', 'Mist', 'Haze', 'Snow', 'Rain'])), 'Low', 'High')\n",
    "\n",
    "    # # Convert Scheduled Arrival Time and Scheduled Departure Time to datetime before calculating duration\n",
    "    # df['Scheduled Arrival Time'] = pd.to_datetime(df['Scheduled Arrival Time'])\n",
    "    # df['Scheduled Departure Time'] = pd.to_datetime(df['Scheduled Departure Time'])\n",
    "    # df['Flight Duration (min)'] = (df['Scheduled Arrival Time'] - df['Scheduled Departure Time']).dt.total_seconds() / 60\n",
    "\n",
    "    # Drop unwanted columns\n",
    "    # df = df.drop(columns=['Type', 'Departure IATA Code', 'Scheduled Departure Time', 'Estimated Departure Time', \n",
    "    # 'Actual Departure Time', 'Arrival Terminal', 'Scheduled Arrival Time', 'Estimated Arrival Time', 'Flight Number',\n",
    "    # 'IATA Flight Number', 'Timestamp', 'Weather Description'])\n",
    "    \n",
    "    # Filter rows where 'Status' is not 'active'\n",
    "    df = df[df['Status'] == 'active']\n",
    "    \n",
    "    # Drop the 'Status' column as it's no longer needed\n",
    "    df = df.drop(columns=['Status'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = custom_preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Departure Gate', 'Departure Delay (min)', 'Scheduled Departure Time',\n",
       "       'Arrival IATA Code', 'Airline Name', 'Temperature', 'Feels Like',\n",
       "       'Pressure', 'Humidity', 'Wind Speed', 'Wind Degree', 'Clouds',\n",
       "       'Weather Main', 'Rain 1h', 'Snow 1h', 'Departure Time of Day',\n",
       "       'Weekday of Departure', 'Weather Severity', 'Season',\n",
       "       'Weekend Departure', 'Visibility'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Scheduled Departure Time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26904\\624355066.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[0mprocessed_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_processed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;31m# Assign weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[0mprocessed_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m \u001b[0mprocessed_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Scheduled Departure Time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Adjust column name as needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[0mprocessed_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weights'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\tfdv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m                     \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_format_argument_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallow_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 )\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\tfdv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   6908\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6909\u001b[0m             \u001b[1;31m# len(by) == 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6911\u001b[0m             \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6912\u001b[1;33m             \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6914\u001b[0m             \u001b[1;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6915\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\tfdv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                 \u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[assignment]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m                 \u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m             )\n\u001b[0;32m   1849\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1850\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1853\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Scheduled Departure Time'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "class DateTimeExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features=None):\n",
    "        self.features = features if features else ['year', 'month', 'day', 'hour', 'weekday']\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_dt = pd.to_datetime(X.iloc[:, 0])\n",
    "        df = pd.DataFrame()\n",
    "        if 'year' in self.features:\n",
    "            df['year'] = X_dt.dt.year\n",
    "        if 'month' in self.features:\n",
    "            df['month'] = X_dt.dt.month\n",
    "        if 'day' in self.features:\n",
    "            df['day'] = X_dt.dt.day\n",
    "        if 'hour' in self.features:\n",
    "            df['hour'] = X_dt.dt.hour\n",
    "        if 'weekday' in self.features:\n",
    "            df['weekday'] = X_dt.dt.weekday\n",
    "        return df\n",
    "\n",
    "    # Let's make sure to handle feature naming properly for custom transformer\n",
    "    def get_feature_names_out(self, input_features):\n",
    "        return self.transform(pd.DataFrame(columns=input_features)).columns.tolist()\n",
    "\n",
    "# Setup your column transformers and pipelines\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "numerical_transformer = Pipeline([\n",
    "    ('imputer', KNNImputer(n_neighbors=5)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "date_transformer = DateTimeExtractor()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_transformer, numerical_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols),\n",
    "    ('date', date_transformer, ['Scheduled Departure Time'])\n",
    "])\n",
    "\n",
    "# Pipeline definition\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Function to extract feature names across transformers\n",
    "def get_feature_names(column_transformer):\n",
    "    feature_names = []\n",
    "    \n",
    "    # Loop through all transformers\n",
    "    for name, transformer, columns in column_transformer.transformers_[:-1]:  # last one is remainder\n",
    "        if hasattr(transformer, 'get_feature_names_out'):\n",
    "            transformer_feature_names = transformer.get_feature_names_out(columns)\n",
    "        else:\n",
    "            transformer_feature_names = columns if isinstance(columns, (np.ndarray, list)) else [columns]\n",
    "        feature_names.extend(transformer_feature_names)\n",
    "    \n",
    "    return feature_names\n",
    "\n",
    "# Apply the pipeline and extract the DataFrame\n",
    "X_processed = pipeline.fit_transform(df)\n",
    "feature_names = get_feature_names(preprocessor)\n",
    "processed_df = pd.DataFrame(X_processed, columns=feature_names, index=df.index)\n",
    "\n",
    "# Assign weights\n",
    "processed_df = shuffle(processed_df, random_state=42)\n",
    "processed_df.sort_values('Scheduled Departure Time', ascending=True, inplace=True)  # Adjust column name as needed\n",
    "weights = np.linspace(start=0.1, stop=1.0, num=len(processed_df))\n",
    "processed_df['weights'] = weights\n",
    "\n",
    "print(processed_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed dataset\n",
    "processed_df.to_csv('final-weather-flight-data/full_processed_dataset_YUL-Flights-Weather.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
